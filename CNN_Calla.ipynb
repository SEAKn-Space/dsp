{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4932c5b-1610-4fbc-82ae-755dca035329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.90147125e-03, -2.34581786e-03, -7.45061261e-04,\n",
       "        -5.34572452e-03, -5.78941777e-03, -3.69683490e-03,\n",
       "        -4.97868750e-03, -6.56572822e-03, -9.04932246e-03,\n",
       "        -4.83668642e-03, -1.00837136e-02, -4.53815702e-03,\n",
       "        -4.31498839e-03, -5.13423281e-03, -6.07567281e-03,\n",
       "         1.18665886e-03, -4.65670088e-03, -6.95332745e-03,\n",
       "        -6.66823424e-03, -6.43977243e-03, -3.82532272e-03,\n",
       "        -8.38821847e-03, -1.01344110e-02, -6.90073194e-03,\n",
       "        -9.62839276e-03, -1.55354582e-03, -2.88469438e-03,\n",
       "        -4.51788818e-03,  3.41027649e-03,  7.41052255e-03,\n",
       "         3.35769332e-03,  7.62627879e-03,  8.82679410e-03,\n",
       "         3.42824613e-03,  1.84083998e-03,  6.41621463e-03,\n",
       "        -1.63305740e-04, -2.24135863e-03, -5.19226259e-03,\n",
       "        -3.63920978e-03, -1.01316329e-02, -6.39987178e-03,\n",
       "        -6.06458448e-03, -7.66557641e-03, -3.44835571e-03,\n",
       "         4.42530581e-04,  2.56719789e-03,  4.74519981e-03,\n",
       "         4.66336496e-03,  6.47741836e-03,  8.53952859e-03,\n",
       "         4.98457067e-03,  1.83550685e-04,  2.53180624e-04,\n",
       "        -2.90070497e-03, -5.35907457e-03, -9.30814818e-03,\n",
       "        -5.05294139e-03, -4.83987946e-03,  1.17973956e-04,\n",
       "        -5.48875541e-04,  8.79733358e-04,  6.80832937e-03,\n",
       "         8.02225806e-03,  8.17798451e-03,  6.84361206e-03,\n",
       "         3.34831537e-03,  2.62019620e-03, -2.50967545e-03,\n",
       "        -6.09290495e-04, -8.00378062e-03, -1.06874220e-02,\n",
       "        -8.18693638e-03, -9.52030625e-03, -4.64970525e-03,\n",
       "        -1.15614315e-03,  2.20692437e-03,  4.98547312e-03,\n",
       "         2.16765120e-03,  6.35635434e-03,  1.04583083e-02,\n",
       "         7.48503441e-03,  6.23615831e-03,  2.93730758e-03,\n",
       "         1.16433017e-03,  2.31683560e-04, -4.89262352e-03,\n",
       "        -3.32372938e-03, -6.60865707e-03, -4.91313590e-03,\n",
       "        -7.29229115e-03, -6.01531472e-03, -1.28758221e-03,\n",
       "         4.22199519e-04,  2.63322057e-04,  3.07579036e-03,\n",
       "         3.98740964e-03,  3.42952716e-03,  2.69522471e-03,\n",
       "         7.13837426e-03,  6.24447502e-03,  6.12162845e-03,\n",
       "         5.42381825e-03,  1.00702723e-03,  9.82678146e-04,\n",
       "         1.36985769e-03,  3.53600271e-03,  4.30495711e-03,\n",
       "         8.39837268e-03,  8.00060481e-03,  6.66820211e-03,\n",
       "         8.24876036e-03,  6.43996848e-03,  1.07639674e-02,\n",
       "         6.80366065e-03,  2.71986006e-03,  6.70633817e-05,\n",
       "         2.20027729e-03,  9.56511474e-04, -1.03281380e-03,\n",
       "        -5.32025425e-03, -7.41181010e-03, -7.29165785e-03,\n",
       "         1.09607929e-04, -3.40843061e-03, -3.26823536e-03,\n",
       "        -3.04144341e-03,  5.69031201e-03],\n",
       "       [-7.79554341e-03, -7.81637430e-03, -4.01966693e-03,\n",
       "        -5.11350809e-03, -5.93952276e-03, -6.56990008e-03,\n",
       "        -5.58479084e-03, -5.29769063e-03,  2.10239770e-04,\n",
       "        -6.04724884e-03, -7.05299387e-03, -7.68376375e-03,\n",
       "        -6.82943454e-03, -5.26323123e-03, -4.28441120e-03,\n",
       "        -8.23529437e-03, -8.87948647e-03, -6.65624905e-03,\n",
       "        -8.73264484e-03, -4.15312545e-03, -8.15828983e-03,\n",
       "        -6.02711225e-03, -1.29826628e-02, -6.86788373e-03,\n",
       "        -6.74923463e-03, -4.03721631e-03, -7.78408628e-03,\n",
       "        -5.31384535e-03,  3.21187358e-03, -5.00479387e-03,\n",
       "         1.21510553e-03,  7.24387297e-04,  4.43488779e-03,\n",
       "         8.31250008e-03,  8.83207936e-03,  5.92549751e-03,\n",
       "         8.33821017e-03,  7.18796719e-03,  8.16119369e-03,\n",
       "         8.70451611e-03,  6.50418410e-03,  4.39436361e-03,\n",
       "         2.82485667e-03,  2.16366793e-03,  5.20329364e-03,\n",
       "         7.40603730e-03,  5.30307589e-04,  5.02638612e-03,\n",
       "         4.79635131e-03,  8.92056711e-03,  7.27958838e-03,\n",
       "         4.10888717e-03, -1.64091331e-03,  3.21661792e-04,\n",
       "        -4.35043173e-03, -5.34027210e-03, -6.72172802e-03,\n",
       "        -4.10642568e-03, -5.31335222e-03, -4.56618797e-03,\n",
       "        -4.76121577e-03, -2.62099039e-03,  2.64574075e-03,\n",
       "         7.91667867e-03,  8.10154900e-03,  8.56091641e-03,\n",
       "         5.86885307e-03,  9.08290315e-03,  2.78104120e-03,\n",
       "        -4.58178995e-03, -7.84578675e-04,  1.90194871e-03,\n",
       "        -5.14773373e-03, -9.67547111e-03, -7.38797616e-03,\n",
       "        -8.74937605e-03, -4.41817427e-03, -1.72313442e-03,\n",
       "        -3.09234415e-03, -8.44296359e-04,  7.02607492e-03,\n",
       "         9.47602745e-03,  3.66653665e-03,  9.18463711e-03,\n",
       "         4.36038384e-03,  8.22377671e-03,  8.38071760e-03,\n",
       "         7.23750377e-03,  3.06395115e-03,  7.47481966e-03,\n",
       "         2.92272819e-03,  5.05259214e-03,  3.31492280e-04,\n",
       "         9.30912420e-03,  4.62912722e-03,  6.58604736e-03,\n",
       "         5.48608275e-03,  6.39372645e-03,  5.06807957e-03,\n",
       "         5.56591107e-03,  6.81962399e-03,  9.10460111e-03,\n",
       "         8.39264598e-03,  8.71987082e-03,  1.01424716e-02,\n",
       "         7.58514786e-03,  4.81515424e-03,  5.65553736e-03,\n",
       "         2.65674363e-03, -2.35611829e-03, -5.01084095e-03,\n",
       "        -2.79374560e-03, -4.82371496e-03, -4.45631938e-03,\n",
       "        -2.13764841e-03, -1.70917076e-03, -2.75444356e-03,\n",
       "        -2.13405839e-03, -3.32542462e-04, -5.56470884e-04,\n",
       "         8.08902271e-03,  6.66311011e-03,  7.31658423e-03,\n",
       "         5.54266246e-03,  5.34808449e-03,  1.03219617e-02,\n",
       "         8.41505732e-03,  5.44548174e-03]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandasData = pd.DataFrame(data)\n",
    "#pandasData.memory_usage\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "# load data\n",
    "data = pd.read_pickle(\".\\\\RML2016.10a\\\\RML2016.10a_dict.pkl\", compression='infer')\n",
    "qpsk_2_data_all = data[('QPSK', 2)]\n",
    "bpsk_2_data_all = data[('BPSK', 2)]\n",
    "\n",
    "# labels\n",
    "qpsk_labels = [0] * 1000  # QPSK = 0\n",
    "bpsk_labels = [1] * 1000  # BPSK = 1\n",
    "\n",
    "# combine the data lables\n",
    "data_combined = np.concatenate((qpsk_2_data_all, bpsk_2_data_all), axis=0)\n",
    "labels_combined = qpsk_labels + bpsk_labels\n",
    "qpsk_2_data_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2f996e-e960-4000-88a9-790484709d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpsk norm tensor([[ 0.3931,  0.1058,  0.2165,  0.1036, -0.2535,  0.2177, -0.1325,  0.0406,\n",
      "         -0.0508, -0.4125, -0.1632, -0.2335, -0.0145, -0.2577,  0.1194, -0.1942,\n",
      "         -0.6206,  0.0697,  0.2044, -0.3668,  0.0674, -0.2717,  0.4861, -0.1844,\n",
      "          0.2618, -0.1605,  0.2926,  0.1440,  0.2854,  0.5265,  0.1897,  0.2028,\n",
      "          0.2990, -0.0814,  0.2161, -0.1558,  0.0926,  0.1711,  0.1701, -0.2396,\n",
      "         -0.4849, -0.0088, -0.1630, -1.0000, -0.4429,  0.0955, -0.5022,  0.0499,\n",
      "          0.4724,  0.1329,  0.2341,  0.2627,  0.1586,  0.0952,  0.0598,  0.1518,\n",
      "          0.1579, -0.0184,  0.3549,  0.1710,  0.3485, -0.1053,  0.2578,  0.0291,\n",
      "          0.2053,  1.0000, -0.0090,  0.2671, -0.1268, -0.1246,  0.3915, -0.1319,\n",
      "          0.0191,  0.0581, -0.2850, -0.1924, -0.5802, -0.4047, -0.0812, -0.3177,\n",
      "         -0.2312, -0.6280, -0.2524,  0.0702,  0.0185, -0.2254,  0.3336,  0.0816,\n",
      "          0.1644,  0.3294,  0.2283,  0.1577,  0.0829, -0.4049, -0.3154, -0.1680,\n",
      "          0.0349, -0.3961,  0.2033, -0.3365, -0.1483,  0.0702, -0.1404, -0.1685,\n",
      "         -0.0418,  0.0191,  0.1323, -0.1486, -0.2703, -0.0987,  0.0199, -0.3150,\n",
      "         -0.0657,  0.8052,  0.5115,  0.4046, -0.1101, -0.1617, -0.1191,  0.0011,\n",
      "         -0.2582, -0.0806, -0.2018, -0.4056, -0.1446, -0.0674, -0.1274,  0.1618],\n",
      "        [-0.1262,  0.0601, -0.0807,  0.2281,  0.6022,  0.6372,  0.3615,  0.5821,\n",
      "          0.7042,  0.5496, -0.0169, -0.4630, -0.1374, -0.4713, -0.5123, -0.7329,\n",
      "         -0.5676, -0.6270, -0.3894, -0.6841, -0.4499, -0.4081, -0.1487, -0.2961,\n",
      "         -0.2366, -1.0000, -0.3807, -0.6192, -0.3149, -0.9649, -0.2660, -0.4088,\n",
      "         -0.1110, -0.2856,  0.4668,  0.3194,  0.4671,  0.6235,  0.9534,  0.5903,\n",
      "          0.3500,  0.3646,  0.1294,  0.0473, -0.5878, -0.5102, -0.6618, -0.5693,\n",
      "         -0.6075, -0.5812, -0.5599, -0.4493, -0.2738, -0.1233, -0.2223, -0.6689,\n",
      "         -0.4893, -0.6657, -0.3130, -0.7305, -0.6080, -0.5091, -0.4855, -0.3862,\n",
      "         -0.1335, -0.1950,  0.0137,  0.1638,  0.1942,  0.4372,  0.2231,  0.8694,\n",
      "          0.6569,  0.7619,  0.8319,  0.6062,  0.5707,  0.4711,  0.5796,  0.4015,\n",
      "          0.4200,  0.2493, -0.0769, -0.0691, -0.3418, -0.5643, -0.6487, -0.2862,\n",
      "         -0.5171,  0.0504,  0.2429,  0.2309, -0.1126,  0.8146,  0.7492,  0.6779,\n",
      "          1.0000,  0.8150,  0.5857,  0.9625,  0.5591,  0.4679,  0.5640,  0.2307,\n",
      "          0.1477,  0.2543,  0.0323, -0.5407, -0.4628, -0.6211, -0.7003, -0.7532,\n",
      "         -0.4385, -0.1034,  0.1291,  0.7777,  0.6377,  0.3825,  0.6168,  0.6552,\n",
      "          0.4867,  0.1352, -0.0109, -0.2075, -0.4486, -0.6018, -0.6147, -0.6778]])\n",
      "bpsk label 1\n",
      "qpsk norm tensor([[-0.5538, -0.2223, -0.0730, -0.5020, -0.5433, -0.3482, -0.4678, -0.6157,\n",
      "         -0.8473, -0.4545, -0.9437, -0.4267, -0.4059, -0.4823, -0.5700,  0.1071,\n",
      "         -0.4377, -0.6519, -0.6253, -0.6040, -0.3602, -0.7856, -0.9484, -0.6470,\n",
      "         -0.9013, -0.1484, -0.2725, -0.4248,  0.3144,  0.6873,  0.3095,  0.7075,\n",
      "          0.8194,  0.3161,  0.1681,  0.5946, -0.0188, -0.2125, -0.4877, -0.3429,\n",
      "         -0.9482, -0.6003, -0.5690, -0.7183, -0.3251,  0.0377,  0.2358,  0.4388,\n",
      "          0.4312,  0.6003,  0.7926,  0.4612,  0.0135,  0.0200, -0.2740, -0.5032,\n",
      "         -0.8714, -0.4747, -0.4548,  0.0074, -0.0547,  0.0785,  0.6312,  0.7444,\n",
      "          0.7589,  0.6345,  0.3086,  0.2407, -0.2376, -0.0604, -0.7498, -1.0000,\n",
      "         -0.7669, -0.8912, -0.4371, -0.1114,  0.2022,  0.4612,  0.1985,  0.5891,\n",
      "          0.9715,  0.6943,  0.5779,  0.2703,  0.1050,  0.0180, -0.4597, -0.3135,\n",
      "         -0.6197, -0.4616, -0.6835, -0.5644, -0.1236,  0.0358,  0.0210,  0.2832,\n",
      "          0.3682,  0.3162,  0.2477,  0.6620,  0.5786,  0.5672,  0.5021,  0.0903,\n",
      "          0.0881,  0.1241,  0.3261,  0.3978,  0.7794,  0.7424,  0.6181,  0.7655,\n",
      "          0.5969,  1.0000,  0.6308,  0.2500,  0.0027,  0.2016,  0.0856, -0.0999,\n",
      "         -0.4996, -0.6946, -0.6834,  0.0067, -0.3214, -0.3083, -0.2871,  0.5270],\n",
      "        [-0.5548, -0.5566, -0.2308, -0.3247, -0.3956, -0.4497, -0.3651, -0.3405,\n",
      "          0.1322, -0.4048, -0.4911, -0.5452, -0.4719, -0.3375, -0.2535, -0.5926,\n",
      "         -0.6479, -0.4571, -0.6353, -0.2423, -0.5860, -0.4031, -1.0000, -0.4752,\n",
      "         -0.4650, -0.2323, -0.5539, -0.3419,  0.3898, -0.3153,  0.2185,  0.1763,\n",
      "          0.4948,  0.8275,  0.8721,  0.6227,  0.8298,  0.7310,  0.8146,  0.8612,\n",
      "          0.6724,  0.4913,  0.3566,  0.2999,  0.5607,  0.7498,  0.1597,  0.5455,\n",
      "          0.5258,  0.8797,  0.7389,  0.4668, -0.0267,  0.1418, -0.2592, -0.3441,\n",
      "         -0.4627, -0.2382, -0.3418, -0.2777, -0.2944, -0.1108,  0.3412,  0.7936,\n",
      "          0.8094,  0.8489,  0.6178,  0.8937,  0.3528, -0.2790,  0.0468,  0.2774,\n",
      "         -0.3276, -0.7162, -0.5199, -0.6367, -0.2650, -0.0337, -0.1512,  0.0417,\n",
      "          0.7171,  0.9274,  0.4288,  0.9024,  0.4884,  0.8199,  0.8334,  0.7353,\n",
      "          0.3771,  0.7557,  0.3650,  0.5478,  0.1426,  0.9131,  0.5114,  0.6794,\n",
      "          0.5850,  0.6629,  0.5491,  0.5918,  0.6994,  0.8955,  0.8344,  0.8625,\n",
      "          0.9846,  0.7651,  0.5274,  0.5995,  0.3422, -0.0880, -0.3159, -0.1256,\n",
      "         -0.2998, -0.2683, -0.0693, -0.0325, -0.1222, -0.0690,  0.0856,  0.0664,\n",
      "          0.8084,  0.6860,  0.7421,  0.5898,  0.5731,  1.0000,  0.8363,  0.5815]])\n",
      "qpsk label 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# convert labels to NumPy array and then to PyTorch tensor with Long data type bc torch.nn.CrossEntropyLoss requires long Datatype\n",
    "labels_combined = np.array(labels_combined, dtype=np.int64)\n",
    "labels_combined = torch.from_numpy(labels_combined).long()\n",
    "\n",
    "# convert 2 PyTorch tensor\n",
    "data_combined = torch.from_numpy(data_combined).float()\n",
    "\n",
    "# convert labels 2 NumPy array and then 2 PyTorch tensor\n",
    "labels_combined = np.array(labels_combined)\n",
    "labels_combined = torch.from_numpy(labels_combined)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # access a single data sample and label\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        #print(f'raw sample: {sample}')\n",
    "        # Convert sample, min_vals, and max_vals to PyTorch tensors\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        #print(f'raw sample: {sample}')\n",
    "        min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        #print(f'min val {min_vals}')\n",
    "\n",
    "    \n",
    "        max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n",
    "        #print(f'max val {max_vals}')\n",
    "        #normalize\n",
    "        epsilon = 1e-10\n",
    "        normalized_sample = 2 * (sample - min_vals.unsqueeze(1)) / (max_vals.unsqueeze(1) - min_vals.unsqueeze(1) + epsilon) - 1\n",
    "        #print(f'Normalized sample: {normalized_sample}')\n",
    "        return normalized_sample, label\n",
    "\n",
    "#train_dataset = MyDataset(data_train, labels_train)\n",
    "#test_dataset = MyDataset(data_test, labels_test)\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "single_dataset_bpsk = MyDataset(bpsk_2_data_all, bpsk_labels)\n",
    "single_loader_bpsk = DataLoader(single_dataset_bpsk, batch_size=batch_size)\n",
    "\n",
    "single_dataset_qpsk = MyDataset(qpsk_2_data_all, qpsk_labels)\n",
    "single_loader_qpsk = DataLoader(single_dataset_qpsk, batch_size=batch_size)\n",
    "\n",
    "for data, labels in single_dataset_bpsk:\n",
    "    first_data_norm_bpsk = data\n",
    "    first_data_label_norm_bpsk = labels\n",
    "    break\n",
    "\n",
    "for data, labels in single_dataset_qpsk:\n",
    "    first_data_norm_qpsk = data\n",
    "    first_data_label_norm_qpsk = labels\n",
    "    break\n",
    "print(f'bpsk norm {first_data_norm_bpsk}')\n",
    "print(f'bpsk label {first_data_label_norm_bpsk}')\n",
    "\n",
    "print(f'qpsk norm {first_data_norm_qpsk}')\n",
    "print(f'qpsk label {first_data_label_norm_qpsk}')\n",
    "\n",
    "\n",
    "with open('normalized_qpsk_first_sample.npz', 'wb') as file:\n",
    "    np.savez(file, first_data_norm_bpsk.numpy(), first_data_norm_qpsk.numpy())\n",
    "    #np.savez(file, first_data_norm_qpsk.numpy())\n",
    "\n",
    "\n",
    "# break into training + testing\n",
    "test_size = 0.2  # Adjust the test size as needed\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    data_combined, labels_combined, test_size=test_size, random_state=42)\n",
    "\n",
    "train_dataset = MyDataset(data_train, labels_train)\n",
    "test_dataset = MyDataset(data_test, labels_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42d3539-5048-4d23-956d-0443b85e086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2D(\n",
      "  (upsample): Upsample(scale_factor=(1.0, 2.0), mode='bilinear')\n",
      "  (conv1): Conv2d(2, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu1): ReLU()\n",
      "  (adaptive_pool1): AdaptiveAvgPool2d(output_size=(1, 64))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu2): ReLU()\n",
      "  (adaptive_pool2): AdaptiveAvgPool2d(output_size=(1, 32))\n",
      "  (adaptive_avg_pool2d): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        in_channels = 2\n",
    "        # For the 2D conversion, we're assuming height=1 for the input\n",
    "        height = 1\n",
    "        width = 128  # Original length dimension\n",
    "        \n",
    "        # Upsample (adjusted for 2D)\n",
    "        self.upsample = nn.Upsample(scale_factor=(1, 2), mode='bilinear', align_corners=False)  # height stays the same, width is doubled\n",
    "        \n",
    "        # Define 2D convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.maxpool1 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool1 = nn.AdaptiveAvgPool2d((1,64))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #self.maxpool2 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool2 = nn.AdaptiveAvgPool2d((1,32))\n",
    "        \n",
    "        # Adaptive pooling (2D)\n",
    "        self.adaptive_avg_pool2d = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        # Define the fully connected layers (adjusted for adaptive pooling output)\n",
    "        self.fc1 = nn.Linear(128, 256)  # The input features after pooling\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Adjust input shape for 2D processing\n",
    "        x = x.unsqueeze(-2)  # Insert a height dimension of size 1\n",
    "        \n",
    "        # Upsample\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # 2D convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.maxpool1(x)\n",
    "        x = self.adaptive_pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        #x = self.maxpool2(x)\n",
    "        x = self.adaptive_pool2(x)\n",
    "        \n",
    "        # Adaptive average pooling\n",
    "        x = self.adaptive_avg_pool2d(x)\n",
    "        \n",
    "        # Flatten (before fully connected layers)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN2D(2)\n",
    "print(model) #model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54e2d2-fcb2-4a71-b863-f7aa59a73add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a target name or fingerprint you want to deploy on\n",
    "#target = \"DPUCAHX8L_ISA0_SP\"\n",
    "target = \"DPUCVDX8G_ISA3_C32B3\"\n",
    "#DPUCVDX8G\n",
    "# Initialize inspector with target\n",
    "inspector = Inspector(target)\n",
    "# Note: visualization of inspection results relies on the dot engine.If you don't install dot successfully, set 'image_format = None' when inspecting.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN2D(2)\n",
    "\n",
    "#dummy_data, labels = train_loader\n",
    "#data_dummy = []\n",
    "for data, labels in train_loader:\n",
    "    data_dummy = data\n",
    "    break\n",
    "print(type(data_dummy))\n",
    "print(data_dummy.shape)\n",
    "dummy_input = torch.randn(1, 2, 128)\n",
    "print(dummy_input)\n",
    "\n",
    "inspector.inspect(model, (data_dummy.clone().detach().requires_grad_(True)), device=device, output_dir=\"inspect\", image_format=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5048bad-9ef2-4d9c-8310-5968cc0ec044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] Loss: 0.0040\n",
      "Epoch [2/3] Loss: 0.0014\n",
      "Epoch [3/3] Loss: 0.1403\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "\n",
    "# loss function and optimizer definition\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model in training mode\n",
    "    \n",
    "    for data, labels in train_loader:\n",
    "        #print(labels)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(data)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    # print loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bca87b-4e45-49c8-8162-c73f93981eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            outputs = model(data)\n",
    "            print(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # predicted and actual labels\n",
    "            for i in range(len(labels)):\n",
    "                print(f'Predicted: {predicted[i]}, Actual: {labels[i]}')\n",
    "            accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "#accuracy_orig_model = evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805c74e4-c560-4f19-b490-3e58f3d82f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5538, -0.2223, -0.0730, -0.5020, -0.5433, -0.3482, -0.4678,\n",
      "          -0.6157, -0.8473, -0.4545, -0.9437, -0.4267, -0.4059, -0.4823,\n",
      "          -0.5700,  0.1071, -0.4377, -0.6519, -0.6253, -0.6040, -0.3602,\n",
      "          -0.7856, -0.9484, -0.6470, -0.9013, -0.1484, -0.2725, -0.4248,\n",
      "           0.3144,  0.6873,  0.3095,  0.7075,  0.8194,  0.3161,  0.1681,\n",
      "           0.5946, -0.0188, -0.2125, -0.4877, -0.3429, -0.9482, -0.6003,\n",
      "          -0.5690, -0.7183, -0.3251,  0.0377,  0.2358,  0.4388,  0.4312,\n",
      "           0.6003,  0.7926,  0.4612,  0.0135,  0.0200, -0.2740, -0.5032,\n",
      "          -0.8714, -0.4747, -0.4548,  0.0074, -0.0547,  0.0785,  0.6312,\n",
      "           0.7444,  0.7589,  0.6345,  0.3086,  0.2407, -0.2376, -0.0604,\n",
      "          -0.7498, -1.0000, -0.7669, -0.8912, -0.4371, -0.1114,  0.2022,\n",
      "           0.4612,  0.1985,  0.5891,  0.9715,  0.6943,  0.5779,  0.2703,\n",
      "           0.1050,  0.0180, -0.4597, -0.3135, -0.6197, -0.4616, -0.6835,\n",
      "          -0.5644, -0.1236,  0.0358,  0.0210,  0.2832,  0.3682,  0.3162,\n",
      "           0.2477,  0.6620,  0.5786,  0.5672,  0.5021,  0.0903,  0.0881,\n",
      "           0.1241,  0.3261,  0.3978,  0.7794,  0.7424,  0.6181,  0.7655,\n",
      "           0.5969,  1.0000,  0.6308,  0.2500,  0.0027,  0.2016,  0.0856,\n",
      "          -0.0999, -0.4996, -0.6946, -0.6834,  0.0067, -0.3214, -0.3083,\n",
      "          -0.2871,  0.5270],\n",
      "         [-0.5548, -0.5566, -0.2308, -0.3247, -0.3956, -0.4497, -0.3651,\n",
      "          -0.3405,  0.1322, -0.4048, -0.4911, -0.5452, -0.4719, -0.3375,\n",
      "          -0.2535, -0.5926, -0.6479, -0.4571, -0.6353, -0.2423, -0.5860,\n",
      "          -0.4031, -1.0000, -0.4752, -0.4650, -0.2323, -0.5539, -0.3419,\n",
      "           0.3898, -0.3153,  0.2185,  0.1763,  0.4948,  0.8275,  0.8721,\n",
      "           0.6227,  0.8298,  0.7310,  0.8146,  0.8612,  0.6724,  0.4913,\n",
      "           0.3566,  0.2999,  0.5607,  0.7498,  0.1597,  0.5455,  0.5258,\n",
      "           0.8797,  0.7389,  0.4668, -0.0267,  0.1418, -0.2592, -0.3441,\n",
      "          -0.4627, -0.2382, -0.3418, -0.2777, -0.2944, -0.1108,  0.3412,\n",
      "           0.7936,  0.8094,  0.8489,  0.6178,  0.8937,  0.3528, -0.2790,\n",
      "           0.0468,  0.2774, -0.3276, -0.7162, -0.5199, -0.6367, -0.2650,\n",
      "          -0.0337, -0.1512,  0.0417,  0.7171,  0.9274,  0.4288,  0.9024,\n",
      "           0.4884,  0.8199,  0.8334,  0.7353,  0.3771,  0.7557,  0.3650,\n",
      "           0.5478,  0.1426,  0.9131,  0.5114,  0.6794,  0.5850,  0.6629,\n",
      "           0.5491,  0.5918,  0.6994,  0.8955,  0.8344,  0.8625,  0.9846,\n",
      "           0.7651,  0.5274,  0.5995,  0.3422, -0.0880, -0.3159, -0.1256,\n",
      "          -0.2998, -0.2683, -0.0693, -0.0325, -0.1222, -0.0690,  0.0856,\n",
      "           0.0664,  0.8084,  0.6860,  0.7421,  0.5898,  0.5731,  1.0000,\n",
      "           0.8363,  0.5815]]])\n",
      "tensor([[ 2.5404, -2.2988]])\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "C:\\Users\\calla\\AppData\\Local\\Temp\\ipykernel_19156\\2117244470.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_single (model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in single_loader_qpsk:\n",
    "            print(data)\n",
    "            outputs = model(data)\n",
    "            print(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # predicted and actual labels\n",
    "            for i in range(len(labels)):\n",
    "                print(f'Predicted: {predicted[i]}, Actual: {labels[i]}')\n",
    "                break\n",
    "            accuracy = 100 * correct / total\n",
    "            break\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "accuracy_orig_model = evaluate_single(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8825c3-893b-43d8-979c-19db391196bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5db792-d1f4-4976-b863-5fcec220b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trainedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_nndct.apis import torch_quantizer, dump_xmodel\n",
    "\n",
    "\n",
    "\n",
    "quantizer = torch_quantizer(\"calib\", model, (dummy_input))\n",
    "quant_model = quantizer.quant_model # is quantize aware\n",
    "\n",
    "#accl_gen, acc4_gen, loss_get = evaluate(quant_model, val_loader, criterion)\n",
    "# evaluate the model on test data\n",
    "accuarcy_quant_model = evaluate(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f336f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.export_quant_config() # creates quantizer config.json\n",
    "\n",
    "quantizer.export_torch_script #exports [model_name]_int.pt\n",
    "quantizer.export_onnx_model() #exports [model_name]_int.onnx\n",
    "\n",
    "quantizer.export_xmodel(deploy_check=True) # in therory exports xmodel, but exports [model_name].py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f988dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
