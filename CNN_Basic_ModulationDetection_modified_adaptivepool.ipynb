{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c9b349-2f42-4b8f-b8d5-a1f64c5a5735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_nndct\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_nndct import Inspector\n",
    "batch_size = 1\n",
    "# load data\n",
    "data = pd.read_pickle(\"RML2016.10a_dict.pkl\", compression='infer')\n",
    "qpsk_2_data_all = data[('QPSK', 2)]\n",
    "bpsk_2_data_all = data[('BPSK', 2)]\n",
    "\n",
    "# labels\n",
    "qpsk_labels = [0] * 1000  # QPSK = 0\n",
    "bpsk_labels = [1] * 1000  # BPSK = 1\n",
    "\n",
    "# combine the data lables\n",
    "data_combined = np.concatenate((qpsk_2_data_all, bpsk_2_data_all), axis=0)\n",
    "labels_combined = qpsk_labels + bpsk_labels\n",
    "\n",
    "# convert labels to NumPy array and then to PyTorch tensor with Long data type\n",
    "labels_combined = np.array(labels_combined, dtype=np.int64)\n",
    "labels_combined = torch.from_numpy(labels_combined).long()\n",
    "\n",
    "# convert 2 PyTorch tensor\n",
    "data_combined = torch.from_numpy(data_combined).float()\n",
    "\n",
    "# convert labels 2 NumPy array and then 2 PyTorch tensor\n",
    "labels_combined = np.array(labels_combined)\n",
    "labels_combined = torch.from_numpy(labels_combined)\n",
    "\n",
    "# break into training + testing\n",
    "test_size = 0.2  # Adjust the test size as needed\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    data_combined, labels_combined, test_size=test_size, random_state=42)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # access a single data sample and label\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "    \n",
    "        # Convert sample, min_vals, and max_vals to PyTorch tensors\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
    "        max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n",
    "        \n",
    "        #normalize\n",
    "        epsilon = 1e-10\n",
    "        normalized_sample = 2 * (sample - min_vals.unsqueeze(1)) / (max_vals.unsqueeze(1) - min_vals.unsqueeze(1) + epsilon) - 1\n",
    "    \n",
    "        return normalized_sample, label\n",
    "\n",
    "train_dataset = MyDataset(data_train, labels_train)\n",
    "test_dataset = MyDataset(data_test, labels_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42d3539-5048-4d23-956d-0443b85e086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2D(\n",
      "  (upsample): Upsample(scale_factor=(1.0, 2.0), mode=bilinear)\n",
      "  (conv1): Conv2d(2, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu1): ReLU()\n",
      "  (adaptive_pool1): AdaptiveAvgPool2d(output_size=(1, 64))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu2): ReLU()\n",
      "  (adaptive_pool2): AdaptiveAvgPool2d(output_size=(1, 32))\n",
      "  (adaptive_avg_pool2d): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"class ModifiedToyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2, mode='nearest')  # set mode = \"nearest\"\n",
    "        self.conv = torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.adaptive_avg_pool2d = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.adaptive_avg_pool2d(x)\n",
    "        x = x.permute(0, 2, 3, 1) # insert a permute to cancel out the permute inserted by quantizer.\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# initialize model\n",
    "num_classes = 2 #BPSK / QPSK\n",
    "model = CNN1D(num_classes)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        in_channels = 2\n",
    "        # For the 2D conversion, we're assuming height=1 for the input\n",
    "        height = 1\n",
    "        width = 128  # Original length dimension\n",
    "        \n",
    "        # Upsample (adjusted for 2D)\n",
    "        self.upsample = nn.Upsample(scale_factor=(1, 2), mode='bilinear', align_corners=False)  # height stays the same, width is doubled\n",
    "        \n",
    "        # Define 2D convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.maxpool1 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool1 = nn.AdaptiveAvgPool2d((1,64))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #self.maxpool2 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool2 = nn.AdaptiveAvgPool2d((1,32))\n",
    "        \n",
    "        # Adaptive pooling (2D)\n",
    "        self.adaptive_avg_pool2d = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        # Define the fully connected layers (adjusted for adaptive pooling output)\n",
    "        self.fc1 = nn.Linear(128, 256)  # The input features after pooling\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Adjust input shape for 2D processing\n",
    "        x = x.unsqueeze(-2)  # Insert a height dimension of size 1\n",
    "        \n",
    "        # Upsample\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # 2D convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.maxpool1(x)\n",
    "        x = self.adaptive_pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        #x = self.maxpool2(x)\n",
    "        x = self.adaptive_pool2(x)\n",
    "        \n",
    "        # Adaptive average pooling\n",
    "        x = self.adaptive_avg_pool2d(x)\n",
    "        \n",
    "        # Flatten (before fully connected layers)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN2D(2)\n",
    "print(model) #model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c54e2d2-fcb2-4a71-b863-f7aa59a73add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Inspector is on.\u001b[0m\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2, 128])\n",
      "tensor([[[-3.0413e-01, -1.1877e+00, -7.7897e-01, -5.9376e-01,  2.6584e-01,\n",
      "           3.0836e-01, -1.2525e+00, -2.2555e-01, -4.9644e-02,  4.1900e-01,\n",
      "           1.4311e+00,  3.7387e-01, -9.2353e-01,  7.0805e-01, -2.9606e+00,\n",
      "          -3.7607e-01, -1.5334e+00,  1.2445e+00,  1.4622e+00,  3.1517e-01,\n",
      "          -1.1061e+00,  6.4145e-01,  1.1340e+00,  3.5031e-02,  4.2173e-01,\n",
      "          -7.1159e-01,  9.8216e-02, -2.5417e+00,  7.2321e-01,  3.1083e-01,\n",
      "           1.5646e+00,  1.3674e+00,  6.6961e-01,  9.6399e-01,  1.3892e+00,\n",
      "           7.2034e-01, -8.0976e-01, -8.6055e-01, -1.9259e-01,  1.9071e-02,\n",
      "          -2.2167e-01, -7.3138e-03,  1.5966e-01,  1.2113e+00, -9.4370e-01,\n",
      "           6.6354e-01, -1.8099e-01,  4.1636e-01, -1.0002e+00, -1.3792e+00,\n",
      "           2.8513e-01,  4.5752e-02, -1.0645e+00, -1.3079e+00, -2.3473e-01,\n",
      "          -5.7306e-01,  1.0545e+00, -5.8274e-01,  7.2737e-01,  1.6759e+00,\n",
      "           7.2980e-01, -4.5969e-01,  7.9714e-01,  8.1729e-01,  2.5148e-01,\n",
      "          -1.1455e+00, -1.5076e+00,  1.0251e+00,  9.1491e-01,  1.5873e+00,\n",
      "          -3.3647e-01, -6.1956e-01,  1.4618e+00,  1.3988e+00, -2.0203e+00,\n",
      "          -1.0689e+00, -7.5000e-01, -5.4693e-01,  1.1394e+00,  6.8753e-01,\n",
      "           2.4049e-01, -2.2838e-02, -1.4714e+00,  8.4313e-01,  4.2686e-01,\n",
      "           7.0097e-01,  1.0620e+00,  1.3337e+00, -2.3933e-01,  1.7241e+00,\n",
      "          -1.1071e+00, -5.0773e-01,  4.9573e-01,  9.0015e-01,  3.8221e-01,\n",
      "          -4.5311e-01, -1.2722e+00,  2.6429e-01,  6.1369e-01,  1.8525e-01,\n",
      "          -1.4657e+00,  5.8847e-01, -2.5001e-01, -1.8868e+00,  4.3957e-01,\n",
      "          -5.4676e-01,  1.4649e+00, -7.0973e-02, -8.8967e-01, -9.4988e-01,\n",
      "          -7.3189e-01, -1.0107e+00, -1.9370e+00,  9.6265e-01,  1.5602e-04,\n",
      "           9.8579e-01, -4.9923e-01, -2.8279e-01,  2.7373e-02,  5.5355e-01,\n",
      "          -3.4606e-02, -1.4317e+00, -4.5507e-01,  1.4046e+00,  1.1324e+00,\n",
      "           9.6351e-01, -1.2349e+00,  1.6008e+00],\n",
      "         [-9.3188e-02, -1.8305e-01, -9.3791e-02, -5.1933e-01,  1.0469e+00,\n",
      "          -8.6735e-01, -1.1120e-01, -3.4262e-01, -2.6664e-01, -5.3441e-02,\n",
      "           7.7911e-02,  6.8871e-01, -8.4524e-01, -3.1768e+00,  1.2187e+00,\n",
      "          -1.3703e+00,  7.0670e-01,  1.7178e-01,  8.5123e-01,  2.2232e-01,\n",
      "           1.4612e+00,  2.0700e-01, -9.5981e-01, -3.3540e-01,  1.3084e-01,\n",
      "           6.8599e-01,  5.3950e-01, -1.7460e-02, -3.8196e-01, -2.7664e-02,\n",
      "          -1.3724e+00, -2.3530e-01,  8.5203e-01, -1.0810e-01,  5.4192e-01,\n",
      "           4.2912e-01, -1.4596e+00, -3.5285e-01, -2.3345e-01, -7.6365e-01,\n",
      "          -5.2936e-01,  3.2532e-01,  1.9812e+00, -1.7353e+00, -8.1045e-01,\n",
      "          -5.0285e-01,  9.8101e-01, -4.0501e-01, -3.8791e-01, -3.5823e-01,\n",
      "          -1.6615e+00,  3.4791e-01,  1.2049e+00,  2.2685e-01, -1.0368e+00,\n",
      "          -3.9360e-01, -3.5798e-01,  1.9195e+00,  6.9214e-01,  1.7937e-01,\n",
      "          -2.7695e-01, -7.3519e-01, -1.2155e+00, -9.2700e-01,  5.1707e-01,\n",
      "           9.5964e-01,  9.4975e-01,  3.5946e-01,  1.4189e+00,  9.3251e-01,\n",
      "           1.2697e+00, -2.4964e-01,  5.8006e-01,  1.7469e+00,  1.5562e+00,\n",
      "           1.3057e+00, -1.1859e+00, -1.0474e+00,  1.6665e+00,  2.1599e+00,\n",
      "           4.9954e-01,  1.9769e+00, -3.7822e-01,  1.2499e+00,  2.0790e-01,\n",
      "          -1.2258e+00, -6.9577e-02, -3.7157e-01, -6.3687e-03,  6.4485e-01,\n",
      "          -2.5653e-01,  2.3961e-01, -3.5958e-01, -1.6692e+00, -1.0235e+00,\n",
      "           3.9771e-01, -5.6476e-01, -2.2482e+00, -5.4833e-01, -1.9824e+00,\n",
      "           8.7391e-01,  1.2108e+00,  1.2286e+00,  8.2690e-01,  1.2954e+00,\n",
      "          -2.5535e+00,  1.6998e+00,  1.1531e+00,  1.3103e-01, -8.4595e-01,\n",
      "          -1.2191e+00,  8.6948e-01,  1.4577e-01, -1.5445e+00,  5.3158e-01,\n",
      "          -3.2551e-01, -2.0138e-01, -3.0511e-01, -3.9353e-01, -6.2224e-02,\n",
      "          -1.6208e+00,  5.8251e-01,  1.0316e+00,  4.4619e-01, -5.1216e-01,\n",
      "          -9.0744e-01, -9.1814e-01,  9.3365e-02]]])\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Start to inspect model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cpu'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing CNN2D...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model nndct_st_CNN2D_ed is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152540/822561179.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "/tmp/ipykernel_152540/822561179.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "/tmp/ipykernel_152540/822561179.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n",
      "██████████████████████████████████████████████████| 16/16 [00:00<00:00, 2321.38it/s, OpInfo: name = return_0, type = Return]                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(inspect/CNN2D.py)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN]: CNN2D::507 is not tensor.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Linear[fc1]/ret.19, op type:nndct_dense, output shape: [1, 256]\n",
      "node name:CNN2D::CNN2D/ReLU[relu3]/ret.21, op type:nndct_relu, output shape: [1, 256]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Conv2d[conv2]/ret.11, op type:nndct_conv2d, output shape: [1, 1, 64, 128]\n",
      "node name:CNN2D::CNN2D/ReLU[relu2]/ret.13, op type:nndct_relu, output shape: [1, 1, 64, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Conv2d[conv1]/ret.7, op type:nndct_conv2d, output shape: [1, 1, 256, 64]\n",
      "node name:CNN2D::CNN2D/ReLU[relu1]/ret.9, op type:nndct_relu, output shape: [1, 1, 256, 64]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.3, op type:nndct_reshape, output shape: [1, 2, 1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.3_swim_transpose_0, op type:nndct_permute, output shape: [1, 1, 128, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.17, op type:nndct_reshape, output shape: [1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_pool2]/486, op type:nndct_avgpool, output shape: [1, 1, 32, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_avg_pool2d]/504, op type:nndct_avgpool, output shape: [1, 1, 1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_pool1]/446, op type:nndct_avgpool, output shape: [1, 1, 64, 64]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for resize_fix_7:\n",
      "node name:CNN2D::CNN2D/Upsample[upsample]/ret.5, op type:nndct_resize, output shape: [1, 1, 256, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_20:\n",
      "node name:CNN2D::CNN2D/Linear[fc2]/ret, op type:nndct_dense, output shape: [1, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The operators assigned to the CPU are as follows(see more details in 'inspect/inspect_DPUCVDX8G_ISA3_C32B3.txt'):\u001b[0m\n",
      "node name                            op Type        hardware constraints\n",
      "-----------------------------------  -------------  -----------------------------------------------------------------------------------------------\n",
      "CNN2D::CNN2D/ret.3                   nndct_reshape  The input of reshape is not on DPU.\n",
      "CNN2D::CNN2D/ret.3_swim_transpose_0  nndct_permute  xir::Op{name = CNN2D__CNN2D_ret_3_swim_transpose_0, type = transpose} has been assigned to CPU.\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finish inspecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "I20240227 10:14:59.096123 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.096146 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.096150 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.096243 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_dense_nndct_relu_8ZfdOuePFXBRi2pJ, with op num: 9\n",
      "I20240227 10:14:59.096248 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.100780 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.100800 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.103451 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.103459 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.103462 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.103504 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_conv2d_nndct_relu_JOX9d0plEskmZ4fh, with op num: 9\n",
      "I20240227 10:14:59.103507 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.106324 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.106339 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.108716 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.108723 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.108726 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.108762 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_conv2d_nndct_relu_TQ8mxPh34OaJfKCk, with op num: 9\n",
      "I20240227 10:14:59.108764 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.111004 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.111021 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.115370 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.115384 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.115388 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.115447 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_reshape_72WRhd4XHMjQGK9U, with op num: 9\n",
      "I20240227 10:14:59.115451 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.116739 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.116757 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.118633 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.118639 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.118643 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.118678 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_permute_BLzSGhbgMy9N3EJr, with op num: 4\n",
      "I20240227 10:14:59.118681 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "W20240227 10:14:59.119886 152540 PartitionPass.cpp:4160] [UNILOG][WARNING] xir::Op{name = CNN2D__CNN2D_ret_3_swim_transpose_0, type = transpose} has been assigned to CPU.\n",
      "I20240227 10:14:59.119932 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 2, DPU subgraph number 0\n",
      "I20240227 10:14:59.119942 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.121505 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.121515 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.121517 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.121568 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_reshape_9m26DoTYKktJ7sNI, with op num: 7\n",
      "I20240227 10:14:59.121570 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.122743 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.122758 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.124778 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.124785 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.124788 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.124815 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_em3MoLJ1g0XQUqEO, with op num: 6\n",
      "I20240227 10:14:59.124819 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.126600 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.126614 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.128274 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.128284 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.128286 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.128326 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_rl8qOTAPmELzHn4V, with op num: 6\n",
      "I20240227 10:14:59.128329 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.130295 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.130313 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.132900 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.132910 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.132913 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.132958 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_YwKPTjBEas2NQJdR, with op num: 6\n",
      "I20240227 10:14:59.132961 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.134841 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.134857 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.137637 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.137646 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.137650 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.137696 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_resize_TlFXcytgs8E7BWxh, with op num: 4\n",
      "I20240227 10:14:59.137699 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.140178 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.140193 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240227 10:14:59.143321 152540 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240227 10:14:59.143328 152540 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240227 10:14:59.143332 152540 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240227 10:14:59.143361 152540 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_dense_YNR7fOqzhxB5Ggwt, with op num: 8\n",
      "I20240227 10:14:59.143364 152540 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240227 10:14:59.146688 152540 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240227 10:14:59.146711 152540 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n"
     ]
    }
   ],
   "source": [
    "# Specify a target name or fingerprint you want to deploy on\n",
    "#target = \"DPUCAHX8L_ISA0_SP\"\n",
    "target = \"DPUCVDX8G_ISA3_C32B3\"\n",
    "#DPUCVDX8G\n",
    "# Initialize inspector with target\n",
    "inspector = Inspector(target)\n",
    "# Note: visualization of inspection results relies on the dot engine.If you don't install dot successfully, set 'image_format = None' when inspecting.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN2D(2)\n",
    "\n",
    "#dummy_data, labels = train_loader\n",
    "#data_dummy = []\n",
    "for data, labels in train_loader:\n",
    "    data_dummy = data\n",
    "    break\n",
    "print(type(data_dummy))\n",
    "print(data_dummy.shape)\n",
    "dummy_input = torch.randn(1, 2, 128)\n",
    "print(dummy_input)\n",
    "\n",
    "inspector.inspect(model, (data_dummy.clone().detach().requires_grad_(True)), device=device, output_dir=\"inspect\", image_format=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35d97a4-c15a-4074-9d1e-5edf7b462d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152540/822561179.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "/tmp/ipykernel_152540/822561179.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "/tmp/ipykernel_152540/822561179.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] Loss: 0.1151\n",
      "Epoch [2/3] Loss: 0.0808\n",
      "Epoch [3/3] Loss: 0.0258\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "\n",
    "# loss function and optimizer definition\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model in training mode\n",
    "    \n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(data)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    # print loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "# evaluate the model on test data\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # predicted and actual labels\n",
    "        for i in range(len(labels)):\n",
    "            print(f'Predicted: {predicted[i]}, Actual: {labels[i]}')\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8825c3-893b-43d8-979c-19db391196bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5db792-d1f4-4976-b863-5fcec220b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trainedModel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
