{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c9b349-2f42-4b8f-b8d5-a1f64c5a5735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/zgzptl2d205bwc_t75yd8fhh0000gn/T/ipykernel_18697/1501639799.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pytorch_nndct\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pytorch_nndct import Inspector\n",
    "batch_size = 1\n",
    "# load data\n",
    "data = pd.read_pickle(\"RML2016.10a_dict.pkl\", compression='infer')\n",
    "qpsk_2_data_all = data[('QPSK', 2)]\n",
    "bpsk_2_data_all = data[('BPSK', 2)]\n",
    "\n",
    "# labels\n",
    "qpsk_labels = [0] * 1000  # QPSK = 0\n",
    "bpsk_labels = [1] * 1000  # BPSK = 1\n",
    "\n",
    "# combine the data lables\n",
    "data_combined = np.concatenate((qpsk_2_data_all, bpsk_2_data_all), axis=0)\n",
    "labels_combined = qpsk_labels + bpsk_labels\n",
    "\n",
    "# convert labels to NumPy array and then to PyTorch tensor with Long data type\n",
    "labels_combined = np.array(labels_combined, dtype=np.int64)\n",
    "labels_combined = torch.from_numpy(labels_combined).long()\n",
    "\n",
    "# convert 2 PyTorch tensor\n",
    "data_combined = torch.from_numpy(data_combined).float()\n",
    "\n",
    "# convert labels 2 NumPy array and then 2 PyTorch tensor\n",
    "labels_combined = np.array(labels_combined)\n",
    "labels_combined = torch.from_numpy(labels_combined)\n",
    "\n",
    "# break into training + testing\n",
    "test_size = 0.2  # Adjust the test size as needed\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    data_combined, labels_combined, test_size=test_size, random_state=42)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # access a single data sample and label\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "    \n",
    "        # Convert sample, min_vals, and max_vals to PyTorch tensors\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
    "        max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n",
    "        \n",
    "        #normalize\n",
    "        epsilon = 1e-10\n",
    "        normalized_sample = 2 * (sample - min_vals.unsqueeze(1)) / (max_vals.unsqueeze(1) - min_vals.unsqueeze(1) + epsilon) - 1\n",
    "    \n",
    "        return normalized_sample, label\n",
    "\n",
    "train_dataset = MyDataset(data_train, labels_train)\n",
    "test_dataset = MyDataset(data_test, labels_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42d3539-5048-4d23-956d-0443b85e086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2D(\n",
      "  (upsample): Upsample(scale_factor=(1.0, 2.0), mode='bilinear')\n",
      "  (conv1): Conv2d(2, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu1): ReLU()\n",
      "  (adaptive_pool1): AdaptiveAvgPool2d(output_size=(1, 64))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "  (relu2): ReLU()\n",
      "  (adaptive_pool2): AdaptiveAvgPool2d(output_size=(1, 32))\n",
      "  (adaptive_avg_pool2d): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"class ModifiedToyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2, mode='nearest')  # set mode = \"nearest\"\n",
    "        self.conv = torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.adaptive_avg_pool2d = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.adaptive_avg_pool2d(x)\n",
    "        x = x.permute(0, 2, 3, 1) # insert a permute to cancel out the permute inserted by quantizer.\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# initialize model\n",
    "num_classes = 2 #BPSK / QPSK\n",
    "model = CNN1D(num_classes)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        in_channels = 2\n",
    "        # For the 2D conversion, we're assuming height=1 for the input\n",
    "        height = 1\n",
    "        width = 128  # Original length dimension\n",
    "        \n",
    "        # Upsample (adjusted for 2D)\n",
    "        self.upsample = nn.Upsample(scale_factor=(1, 2), mode='bilinear', align_corners=False)  # height stays the same, width is doubled\n",
    "        \n",
    "        # Define 2D convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.maxpool1 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool1 = nn.AdaptiveAvgPool2d((1,64))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #self.maxpool2 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        self.adaptive_pool2 = nn.AdaptiveAvgPool2d((1,32))\n",
    "        \n",
    "        # Adaptive pooling (2D)\n",
    "        self.adaptive_avg_pool2d = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        # Define the fully connected layers (adjusted for adaptive pooling output)\n",
    "        self.fc1 = nn.Linear(128, 256)  # The input features after pooling\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.fc2 = nn.Linear(256, 2) #binary classification (BPSK / QPSK) with 1 output neuron\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Adjust input shape for 2D processing\n",
    "        x = x.unsqueeze(-2)  # Insert a height dimension of size 1\n",
    "        \n",
    "        # Upsample\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # 2D convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.maxpool1(x)\n",
    "        x = self.adaptive_pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        #x = self.maxpool2(x)\n",
    "        x = self.adaptive_pool2(x)\n",
    "        \n",
    "        # Adaptive average pooling\n",
    "        x = self.adaptive_avg_pool2d(x)\n",
    "        \n",
    "        # Flatten (before fully connected layers)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN2D()\n",
    "print(model) #model info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c54e2d2-fcb2-4a71-b863-f7aa59a73add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Inspector is on.\u001b[0m\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2, 128])\n",
      "tensor([[[ 1.2419, -0.7442,  0.1608, -2.4847,  0.5102, -1.0885, -0.8666,\n",
      "          -0.2171,  2.3965, -1.4778,  1.0408,  0.7034, -1.0147,  1.5584,\n",
      "           0.2757,  0.0392, -0.4880,  1.2513,  1.0156,  0.1213,  0.3852,\n",
      "           0.4313, -0.2750, -1.2605,  0.0075, -0.2101, -0.9361,  0.3707,\n",
      "           1.6505, -0.2779, -0.6461,  0.6620, -2.1368, -0.4896, -0.7619,\n",
      "          -1.1381, -0.4288,  0.5116,  0.5877,  0.8381,  0.2129, -0.5857,\n",
      "          -0.6041,  0.1553, -0.2945,  1.7447,  0.8721, -1.6685,  0.3773,\n",
      "           0.8339, -0.9704,  0.1246, -0.7313, -1.3037,  0.0848, -2.5284,\n",
      "           1.5076, -0.0527,  0.4899,  0.2916, -1.2697, -0.2319, -0.3756,\n",
      "          -1.5034,  1.0084, -1.2053,  0.0208, -0.0110,  0.5167, -0.3695,\n",
      "           1.2093,  1.6096,  0.2915, -0.8964,  0.1353, -1.1268,  2.6418,\n",
      "           0.3506, -0.3700, -1.0517,  0.3395,  0.6789,  1.7849,  1.0049,\n",
      "           0.3596, -0.0507, -0.5034,  0.3627, -1.3069, -0.6793,  0.2270,\n",
      "          -0.6466,  0.1777, -2.1267, -1.0783,  1.3030,  0.9296,  1.2457,\n",
      "           0.7792, -1.4287, -0.1498,  0.1799, -0.5631, -1.1882,  0.0890,\n",
      "          -0.8296, -0.5018,  0.9154, -0.3392, -0.0320, -0.0219, -0.6665,\n",
      "           0.9759, -0.5932,  0.9734, -0.2854,  1.4791, -0.1757, -1.1237,\n",
      "          -0.5267, -0.4876, -0.0725,  0.5531, -1.7890,  0.3432, -0.5921,\n",
      "          -1.2010,  0.2058],\n",
      "         [-0.1027, -0.9511,  1.3926,  0.7064,  0.0886,  0.2130,  0.0274,\n",
      "           0.0896, -0.1581, -1.5762,  0.7013, -0.1328, -0.5877,  0.6179,\n",
      "          -0.5171,  2.7449, -0.8527,  0.4152, -1.6645, -1.2236, -0.8840,\n",
      "           1.2819,  0.0775, -0.0282,  0.3880, -0.3069, -2.4014, -0.4693,\n",
      "          -0.7003, -0.3702, -0.9777,  1.0874,  0.2289, -0.7938,  1.8083,\n",
      "          -0.4569,  0.2289,  1.6975, -0.3090, -0.6428,  0.4231,  0.5099,\n",
      "           0.1683,  0.0692,  0.0290,  0.0955,  2.0713, -1.4988, -0.1607,\n",
      "          -0.7955,  0.3893,  0.3450,  1.0982,  0.4990, -0.4059, -1.2588,\n",
      "          -2.2167,  0.6168,  0.6139,  0.0243, -1.4413, -1.0410,  1.3499,\n",
      "           0.4192,  0.1163,  2.1208, -2.0858, -0.6835,  0.5415, -0.9708,\n",
      "           0.4389,  0.2706,  1.6812,  1.3331,  0.0947, -1.0234, -1.5943,\n",
      "           1.5915, -0.0357,  0.4212,  0.4446, -0.7584,  0.1444,  0.5044,\n",
      "           1.0888,  0.2908, -0.4964, -0.2965, -0.9400,  0.4062,  0.9634,\n",
      "           1.2810, -0.7433, -0.7921,  1.4668,  1.0035,  0.4439,  0.6472,\n",
      "           1.5644,  1.5126,  0.0963, -0.4686,  0.9152, -0.0674,  1.5819,\n",
      "          -0.4839,  0.7644, -0.1507,  0.3132,  0.7634, -0.9517, -0.2461,\n",
      "           0.1135,  0.1256,  0.1444,  0.2490,  1.1506, -0.3925, -0.4043,\n",
      "          -1.0023,  0.7306, -0.3109,  2.2606,  1.2258, -0.2685, -0.8481,\n",
      "           1.0464, -1.4770]]])\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Start to inspect model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cpu'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing CNN2D...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200599/822561179.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "/tmp/ipykernel_200599/822561179.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "/tmp/ipykernel_200599/822561179.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model nndct_st_CNN2D_ed is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████████████████████████████████████████████| 16/16 [00:00<00:00, 1676.34it/s, OpInfo: name = return_0, type = Return]                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(inspect/CNN2D.py)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN]: CNN2D::507 is not tensor.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Linear[fc1]/ret.19, op type:nndct_dense, output shape: [1, 256]\n",
      "node name:CNN2D::CNN2D/ReLU[relu3]/ret.21, op type:nndct_relu, output shape: [1, 256]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Conv2d[conv2]/ret.11, op type:nndct_conv2d, output shape: [1, 1, 64, 128]\n",
      "node name:CNN2D::CNN2D/ReLU[relu2]/ret.13, op type:nndct_relu, output shape: [1, 1, 64, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_18:\n",
      "node name:CNN2D::CNN2D/Conv2d[conv1]/ret.7, op type:nndct_conv2d, output shape: [1, 1, 256, 64]\n",
      "node name:CNN2D::CNN2D/ReLU[relu1]/ret.9, op type:nndct_relu, output shape: [1, 1, 256, 64]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.17, op type:nndct_reshape, output shape: [1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.3_swim_transpose_0, op type:nndct_permute, output shape: [1, 1, 128, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for reshape_fix_1:\n",
      "node name:CNN2D::CNN2D/ret.3, op type:nndct_reshape, output shape: [1, 2, 1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_pool1]/446, op type:nndct_avgpool, output shape: [1, 1, 64, 64]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_avg_pool2d]/504, op type:nndct_avgpool, output shape: [1, 1, 1, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for pool_fix_4:\n",
      "node name:CNN2D::CNN2D/AdaptiveAvgPool2d[adaptive_pool2]/486, op type:nndct_avgpool, output shape: [1, 1, 32, 128]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for resize_fix_7:\n",
      "node name:CNN2D::CNN2D/Upsample[upsample]/ret.5, op type:nndct_resize, output shape: [1, 1, 256, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Find subgraph for convlike_fix_20:\n",
      "node name:CNN2D::CNN2D/Linear[fc2]/ret, op type:nndct_dense, output shape: [1, 2]\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The operators assigned to the CPU are as follows(see more details in 'inspect/inspect_DPUCVDX8G_ISA3_C32B3.txt'):\u001b[0m\n",
      "node name                            op Type        hardware constraints\n",
      "-----------------------------------  -------------  -----------------------------------------------------------------------------------------------\n",
      "CNN2D::CNN2D/ret.3                   nndct_reshape  The input of reshape is not on DPU.\n",
      "CNN2D::CNN2D/ret.3_swim_transpose_0  nndct_permute  xir::Op{name = CNN2D__CNN2D_ret_3_swim_transpose_0, type = transpose} has been assigned to CPU.\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finish inspecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I20240229 09:17:56.093032 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.093055 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.093060 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.093122 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_dense_nndct_relu_Zq6mEnaGWUs0rhFH, with op num: 9\n",
      "I20240229 09:17:56.093125 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.097330 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.097349 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.099707 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.099715 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.099718 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.099757 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_conv2d_nndct_relu_Hgxq0dEFjsLp8k2G, with op num: 9\n",
      "I20240229 09:17:56.099761 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.103399 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.103422 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.106765 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.106793 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.106801 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.107012 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_conv2d_nndct_relu_Wv07kGRKluBAnm2d, with op num: 9\n",
      "I20240229 09:17:56.107019 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.110397 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.110415 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.113909 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.113919 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.113921 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.113965 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_reshape_TniDspkd0LvhIXm4, with op num: 7\n",
      "I20240229 09:17:56.113966 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.115583 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.115604 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.117197 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.117203 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.117206 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.117238 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_permute_iSGgo8trb1ONmpME, with op num: 4\n",
      "I20240229 09:17:56.117240 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "W20240229 09:17:56.119305 200599 PartitionPass.cpp:4160] [UNILOG][WARNING] xir::Op{name = CNN2D__CNN2D_ret_3_swim_transpose_0, type = transpose} has been assigned to CPU.\n",
      "I20240229 09:17:56.119371 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 2, DPU subgraph number 0\n",
      "I20240229 09:17:56.119386 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.121800 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.121827 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.121831 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.121903 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_reshape_fSAaxpLRGEzU8wru, with op num: 9\n",
      "I20240229 09:17:56.121909 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.124039 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.124061 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.126886 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.126896 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.126900 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.126953 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_dSMDY2x4HL6eBU0T, with op num: 6\n",
      "I20240229 09:17:56.126957 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.129583 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.129601 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.131358 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.131366 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.131369 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.131405 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_TWZvxIGrQDj0s1eU, with op num: 6\n",
      "I20240229 09:17:56.131408 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.133561 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.133577 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.135202 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.135210 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.135211 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.135246 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_avgpool_FKkmEXisvyfbnPue, with op num: 6\n",
      "I20240229 09:17:56.135248 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.138165 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.138193 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.142295 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.142307 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.142310 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.142362 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_resize_vIGS0Uf3CZXLByQ9, with op num: 4\n",
      "I20240229 09:17:56.142365 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.144945 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.144961 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n",
      "I20240229 09:17:56.148217 200599 compile_pass_manager.cpp:352] [UNILOG][INFO] Compile mode: dpu\n",
      "I20240229 09:17:56.148226 200599 compile_pass_manager.cpp:353] [UNILOG][INFO] Debug mode: null\n",
      "I20240229 09:17:56.148228 200599 compile_pass_manager.cpp:357] [UNILOG][INFO] Target architecture: DPUCVDX8G_ISA3_C32B3\n",
      "I20240229 09:17:56.148268 200599 compile_pass_manager.cpp:465] [UNILOG][INFO] Graph name: nndct_dense_kJztK2EM5vDVxfZc, with op num: 8\n",
      "I20240229 09:17:56.148272 200599 compile_pass_manager.cpp:478] [UNILOG][INFO] Begin to compile...\n",
      "I20240229 09:17:56.151335 200599 compile_pass_manager.cpp:489] [UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "I20240229 09:17:56.151348 200599 compile_pass_manager.cpp:504] [UNILOG][INFO] Compile done.\n"
     ]
    }
   ],
   "source": [
    "# Specify a target name or fingerprint you want to deploy on\n",
    "#target = \"DPUCAHX8L_ISA0_SP\"\n",
    "target = \"DPUCVDX8G_ISA3_C32B3\"\n",
    "#DPUCVDX8G\n",
    "# Initialize inspector with target\n",
    "inspector = Inspector(target)\n",
    "# Note: visualization of inspection results relies on the dot engine.If you don't install dot successfully, set 'image_format = None' when inspecting.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN2D(2)\n",
    "\n",
    "#dummy_data, labels = train_loader\n",
    "#data_dummy = []\n",
    "for data, labels in train_loader:\n",
    "    data_dummy = data\n",
    "    break\n",
    "print(type(data_dummy))\n",
    "print(data_dummy.shape)\n",
    "dummy_input = torch.randn(1, 2, 128)\n",
    "print(dummy_input)\n",
    "\n",
    "inspector.inspect(model, (data_dummy.clone().detach().requires_grad_(True)), device=device, output_dir=\"inspect\", image_format=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35d97a4-c15a-4074-9d1e-5edf7b462d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/zgzptl2d205bwc_t75yd8fhh0000gn/T/ipykernel_18697/1501639799.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "/var/folders/j5/zgzptl2d205bwc_t75yd8fhh0000gn/T/ipykernel_18697/1501639799.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "/var/folders/j5/zgzptl2d205bwc_t75yd8fhh0000gn/T/ipykernel_18697/1501639799.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] Loss: 0.3153\n",
      "Epoch [2/3] Loss: 0.3139\n",
      "Epoch [3/3] Loss: 0.3133\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 92.75%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "\n",
    "# loss function and optimizer definition\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model in training mode\n",
    "    \n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(data)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    # print loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "def evaluate (model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # predicted and actual labels\n",
    "            for i in range(len(labels)):\n",
    "                print(f'Predicted: {predicted[i]}, Actual: {labels[i]}')\n",
    "            accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "accuracy_orig_model = evaluate(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8825c3-893b-43d8-979c-19db391196bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtotal\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5db792-d1f4-4976-b863-5fcec220b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trainedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b728ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_CUDA_UNAVAILABLE]: CUDA (HIP) is not available, change device to CPU\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- seakn-ThinkPad-P16s-Gen-1\n",
      "              release --- 6.5.0-17-generic\n",
      "              version --- #17~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jan 16 14:32:32 UTC 2\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 7.5.0\n",
      "               python --- 3.8.6\n",
      "              pytorch --- 1.13.1\n",
      "        vai_q_pytorch --- 3.5.0+60df3f1+torch1.13.1\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_CUDA_UNAVAILABLE]: CUDA (HIP) is not available, change device to CPU.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cpu'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing CNN2D...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model nndct_st_CNN2D_ed is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████████████████████████████████████████████| 16/16 [00:00<00:00, 2723.35it/s, OpInfo: name = return_0, type = Return]                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(quantize_result/CNN2D.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_200599/822561179.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(sample, dtype=torch.float32)\n",
      "/tmp/ipykernel_200599/822561179.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  min_vals = torch.tensor(sample.min(axis=1).values, dtype=torch.float32)\n",
      "/tmp/ipykernel_200599/822561179.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_vals = torch.tensor(sample.max(axis=1).values, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 100.00%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 98.41%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 98.44%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 96.92%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.97%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.01%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.06%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.10%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.14%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.18%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.22%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.26%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.30%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.37%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.40%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.44%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.47%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.50%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.53%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 97.56%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 97.59%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 96.43%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.47%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.51%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.55%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.59%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.63%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.67%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.70%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.74%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.77%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.81%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.84%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.88%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.91%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.94%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 95.96%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.04%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.08%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.12%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 95.19%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.24%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.28%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.37%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.41%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.45%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.50%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.54%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.58%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.61%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.65%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.69%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.73%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.76%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.80%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.83%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.87%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.90%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.93%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.97%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.00%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.03%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.06%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.09%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.12%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 96.15%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.18%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 96.21%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 95.49%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.52%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.56%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.59%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.62%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.65%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.68%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.71%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.74%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.77%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 95.10%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.14%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.17%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.21%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.24%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.27%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.30%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.33%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.36%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.39%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.42%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.45%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.48%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.51%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.54%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.57%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.60%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 95.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.03%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.06%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.09%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.12%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.15%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.18%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.21%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.24%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.27%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.29%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.32%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 95.35%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 95.38%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 94.83%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.86%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.89%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.92%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.94%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.97%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 94.44%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.48%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.51%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.54%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.57%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.59%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.62%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.65%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.68%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.71%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.74%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.76%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 94.27%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.30%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.36%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.39%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.42%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.44%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.47%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.50%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.53%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.55%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.61%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 94.15%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.17%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.20%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.23%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.26%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.29%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.31%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.34%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.37%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.39%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 93.95%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.98%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.01%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.04%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.06%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.09%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.12%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.14%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.17%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.20%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.22%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.25%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.27%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.30%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.32%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.35%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.37%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.40%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.42%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.44%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.47%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.49%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.51%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.54%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.56%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.58%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.61%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.63%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.65%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.67%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.69%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 94.31%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.33%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.35%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.38%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.40%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.42%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.44%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.47%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.49%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.51%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.53%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.55%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.57%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.59%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 94.23%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.25%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.27%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.30%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.32%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.34%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.36%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.38%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.40%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.42%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.44%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.46%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.49%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.51%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.53%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.55%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.57%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.58%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.60%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.62%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.64%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.66%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.68%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.70%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.72%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.74%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.76%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.77%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.79%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.81%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.83%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.85%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 94.52%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.54%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.56%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.58%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.59%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.61%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.63%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 94.31%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.35%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 94.04%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 94.06%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 93.75%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.77%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.79%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.81%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.83%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.85%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.87%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.89%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.91%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.93%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.95%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.97%\n",
      "Predicted: 1, Actual: 0\n",
      "Test Accuracy: 93.67%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 93.38%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.40%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.42%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.44%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.46%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.48%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.50%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.52%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.54%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.56%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.58%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.60%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 93.31%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.35%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.37%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.39%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.41%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.43%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 93.15%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.18%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.20%\n",
      "Predicted: 0, Actual: 1\n",
      "Test Accuracy: 92.92%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 92.94%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 92.96%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 92.98%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.00%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.02%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.04%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.06%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.08%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.10%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.12%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.14%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.16%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.18%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.20%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.22%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.24%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.26%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.28%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.30%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.31%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.33%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.35%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.37%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.39%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.41%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.42%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.44%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.46%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.48%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.50%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.51%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.53%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.55%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.57%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.58%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.60%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.62%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.63%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.65%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.67%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.68%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.70%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.73%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.75%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.77%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.78%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.80%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.81%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.83%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.85%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.86%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.88%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.89%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.91%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.92%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.94%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.95%\n",
      "Predicted: 1, Actual: 1\n",
      "Test Accuracy: 93.97%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 93.98%\n",
      "Predicted: 0, Actual: 0\n",
      "Test Accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "from pytorch_nndct.apis import torch_quantizer, dump_xmodel\n",
    "\n",
    "\n",
    "\n",
    "quantizer = torch_quantizer(\"calib\", model, (dummy_input))\n",
    "quant_model = quantizer.quant_model # is quantize aware\n",
    "\n",
    "#accl_gen, acc4_gen, loss_get = evaluate(quant_model, val_loader, criterion)\n",
    "# evaluate the model on test data\n",
    "accuarcy_quant_model = evaluate(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f336f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(quantize_result/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: CNN2D_int.pt is generated.(quantize_result/CNN2D_int.pt)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: CNN2D_int.onnx is generated.(quantize_result/CNN2D_int.onnx)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "quantizer.export_quant_config() # creates quantizer config.json\n",
    "\n",
    "quantizer.export_torch_script #exports [model_name]_int.pt\n",
    "quantizer.export_onnx_model() #exports [model_name]_int.onnx\n",
    "\n",
    "quantizer.export_xmodel(deploy_check=True) # in therory exports xmodel, but exports [model_name].py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f988dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
